
// This file is automatically generated. Do not edit it directly.
import { createClient } from '@supabase/supabase-js';
import type { Database } from './types';

const SUPABASE_URL = "https://fhyhyfoqzpkzkxbkqcdp.supabase.co";
const SUPABASE_PUBLISHABLE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImZoeWh5Zm9xenBremt4YmtxY2RwIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDY1NjY0ODIsImV4cCI6MjA2MjE0MjQ4Mn0.NluvL4FiDbgKXu_avMaLUgyzQayV4_15vrH64vWfok0";

// Import the supabase client like this:
// import { supabase } from "@/integrations/supabase/client";

export const supabase = createClient<Database>(SUPABASE_URL, SUPABASE_PUBLISHABLE_KEY, {
  auth: {
    persistSession: true,
    autoRefreshToken: true,
    detectSessionInUrl: true,
    storage: typeof window !== 'undefined' ? localStorage : undefined,
    flowType: 'implicit',
  },
  global: {
    headers: {
      'Cache-Control': 'no-cache',
      'Pragma': 'no-cache',
      'X-Client-Info': 'supabase-js/2.x'
    },
    fetch: (url, options) => {
      // Shorter timeout and simpler error handling to avoid QUIC issues
      const timeout = 30000; // 30 seconds
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);
      
      return fetch(url, {
        ...options,
        signal: controller.signal,
        // Force HTTP/1.1 to avoid QUIC protocol issues
        headers: {
          ...options?.headers,
          'Connection': 'keep-alive',
        }
      }).finally(() => clearTimeout(timeoutId));
    }
  },
  db: {
    schema: 'public',
  },
  realtime: {
    params: {
      eventsPerSecond: 10, // Reduced to avoid connection issues
    }
  }
});

// Simplified error handling without excessive retries
let connectionRetries = 0;
const maxRetries = 3;

// Monitor for connection issues
supabase.auth.onAuthStateChange((event, session) => {
  if (event === 'SIGNED_OUT') {
    console.log('User signed out');
    connectionRetries = 0;
  } else if (event === 'USER_UPDATED') {
    console.log('User session updated');
  }
});

// Simple batch operation for large datasets
export const batchOperation = async <T>(items: T[], operationFn: (batch: T[]) => Promise<any>, batchSize = 500) => {
  const batches = [];
  
  for (let i = 0; i < items.length; i += batchSize) {
    batches.push(items.slice(i, i + batchSize));
  }
  
  const results = [];
  for (const batch of batches) {
    try {
      const result = await operationFn(batch);
      results.push(result);
    } catch (error) {
      console.error('Batch operation failed:', error);
      throw error;
    }
  }
  
  return results;
};

// Simplified fetchPaginated without complex retry logic
export const fetchPaginated = async <T = any>(
  tableName: 'admins' | 'voters',
  options: {
    filters?: Record<string, any>;
    orderBy?: string;
    ascending?: boolean;
  } = {}, 
  pageSize = 1000
): Promise<T[]> => {
  const { filters = {}, orderBy = 'created_at', ascending = false } = options;
  
  console.log(`Fetching all ${tableName} records`);

  try {
    // Create a fresh query
    let query = supabase.from(tableName).select('*');
    
    // Add ordering
    query = query.order(orderBy, { ascending });
    
    // Apply filters
    Object.entries(filters).forEach(([key, value]) => {
      if (value !== undefined && value !== null && value !== '') {
        query = query.eq(key, value);
      }
    });

    console.log(`Executing single query for all ${tableName} records`);
    
    const { data, error } = await query;
    
    if (error) {
      console.error(`Error fetching ${tableName}:`, error);
      throw error;
    }
    
    console.log(`Successfully fetched ${data?.length || 0} ${tableName} records`);
    return (data || []) as T[];
    
  } catch (error) {
    console.error('Error in fetchPaginated:', error);
    throw error;
  }
};
