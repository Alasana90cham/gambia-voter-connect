
// This file is automatically generated. Do not edit it directly.
import { createClient } from '@supabase/supabase-js';
import type { Database } from './types';

const SUPABASE_URL = "https://fhyhyfoqzpkzkxbkqcdp.supabase.co";
const SUPABASE_PUBLISHABLE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImZoeWh5Zm9xenBremt4YmtxY2RwIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDY1NjY0ODIsImV4cCI6MjA2MjE0MjQ4Mn0.NluvL4FiDbgKXu_avMaLUgyzQayV4_15vrH64vWfok0";

// Import the supabase client like this:
// import { supabase } from "@/integrations/supabase/client";

// Define types for our RPC functions with simplified typing to avoid excessive depth
interface RPCResponse<T = any> {
  data: T;
  error: Error | null;
}

// Extend SupabaseClient with simplified typing
declare module '@supabase/supabase-js' {
  interface SupabaseClient<Database> {
    rpc(
      fn: 'admin_login' | 'create_admin' | 'delete_admin' | 'add_initial_admins',
      params?: object,
      options?: object
    ): RPCResponse;
  }
}

export const supabase = createClient<Database>(SUPABASE_URL, SUPABASE_PUBLISHABLE_KEY, {
  auth: {
    persistSession: true,
    autoRefreshToken: true,
    detectSessionInUrl: true,
    storage: typeof window !== 'undefined' ? localStorage : undefined,
    flowType: 'implicit', // More secure auth flow
  },
  global: {
    headers: {
      'Cache-Control': 'no-cache',
      'Pragma': 'no-cache',
      'X-Client-Info': 'supabase-js/2.x'
    },
    fetch: (url, options) => {
      // Increased timeout to 20 minutes for very large dataset operations
      const timeout = 1200000; 
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);
      
      return fetch(url, {
        ...options,
        signal: controller.signal,
      }).finally(() => clearTimeout(timeoutId));
    }
  },
  db: {
    schema: 'public',
  },
  realtime: {
    params: {
      eventsPerSecond: 100, // Increased rate limit for more frequent updates
    }
  }
});

// Enhanced connection pooling and request monitoring
let failedRequests = 0;
const maxRetries = 10; // Increased for better resilience with large datasets
const connectionPool = new Set();
const maxPoolSize = 300; // Increased for better concurrency with large datasets

// Simplified handleRequestWithRetry function to avoid excessive type instantiation
const handleRequestWithRetry = async (requestFn) => {
  let retries = 0;
  
  while (retries < maxRetries) {
    try {
      if (connectionPool.size >= maxPoolSize) {
        const delay = 50 * Math.pow(2, retries);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
      
      const requestId = Date.now() + Math.random();
      connectionPool.add(requestId);
      
      const result = await requestFn();
      
      connectionPool.delete(requestId);
      return result;
    } catch (error) {
      retries++;
      console.error(`Supabase request failed (attempt ${retries}/${maxRetries}):`, error);
      
      if (retries >= maxRetries) {
        console.error('Maximum retries reached for Supabase request');
        throw error;
      }
      
      const baseDelay = 200 * Math.pow(2, retries);
      const jitter = Math.random() * 300;
      await new Promise(resolve => setTimeout(resolve, baseDelay + jitter));
    }
  }
};

// Monitor for authentication failures
supabase.auth.onAuthStateChange((event, session) => {
  if (event === 'SIGNED_OUT') {
    console.log('User signed out');
    failedRequests = 0; // Reset counter on sign out
  } else if (event === 'USER_UPDATED') {
    console.log('User session updated');
  }
});

// Enhance original auth methods with retry logic
const originalSignIn = supabase.auth.signInWithPassword;
supabase.auth.signInWithPassword = async (credentials) => {
  return handleRequestWithRetry(async () => {
    try {
      const response = await originalSignIn(credentials);
      if (response.error) {
        failedRequests++;
        if (failedRequests > 5) {
          console.error('Multiple failed login attempts detected');
          setTimeout(() => { failedRequests = 0; }, 15 * 60 * 1000);
        }
      } else {
        failedRequests = 0;
      }
      return response;
    } catch (error) {
      console.error('Supabase auth error:', error);
      throw error;
    }
  });
};

// Add optimized batch operations for handling large datasets
export const batchOperation = async (items, operationFn, batchSize = 750) => {
  const batches = [];
  
  for (let i = 0; i < items.length; i += batchSize) {
    batches.push(items.slice(i, i + batchSize));
  }
  
  const results = [];
  for (const batch of batches) {
    try {
      const result = await operationFn(batch);
      results.push(result);
    } catch (error) {
      console.error('Batch operation failed:', error);
      throw error;
    }
  }
  
  return results;
};

// Complete reimplementation of fetchPaginated with NO record limits
// and multiple fail-safe mechanisms to ensure ALL records are retrieved
export const fetchPaginated = async <T>(
  tableName: 'admins' | 'voters',
  options: {
    filters?: Record<string, any>;
    orderBy?: string;
    ascending?: boolean;
  } = {}, 
  pageSize = 500000  // Use a MASSIVE page size to get all records at once
): Promise<T[]> => {
  const { filters = {}, orderBy = 'created_at', ascending = true } = options;
  const allResults: T[] = [];
  
  console.log(`Starting UNLIMITED paginated fetch for ${tableName} with NO record limits`);

  try {
    // Try direct count first to verify total records
    const { count, error: countError } = await supabase
      .from(tableName)
      .select('*', { count: 'exact', head: true });
    
    if (countError) {
      console.error(`Error getting count for ${tableName}:`, countError);
    } else {
      console.log(`Total records in ${tableName}: ${count}`);
    }
    
    // Primary fetching strategy - get everything at once
    try {
      // Create a fresh query
      let query = supabase.from(tableName).select('*');
      
      // Add ordering
      query = query.order(orderBy, { ascending });
      
      // Apply filters
      Object.entries(filters).forEach(([key, value]) => {
        if (value !== undefined && value !== null && value !== '') {
          // @ts-ignore
          query = query.eq(key, value);
        }
      });

      console.log(`Fetching ALL ${tableName} records at once`);
      
      const { data, error } = await query;
      
      if (error) {
        console.error(`Error fetching all ${tableName} records:`, error);
      } else if (data) {
        console.log(`Successfully retrieved all ${data.length} records at once`);
        allResults.push(...data as T[]);
      }
      
      return allResults;
      
    } catch (allAtOnceError) {
      console.error(`Error fetching all records at once:`, allAtOnceError);
    }
    
    // Fallback to chunked pagination if getting all at once fails
    if (allResults.length === 0) {
      console.log("Falling back to chunked pagination strategy");
      
      // Strategy 2: Standard pagination using range
      let page = 0;
      let hasMore = true;
      const maxPages = 10000; // Virtually unlimited
      const fallbackPageSize = 1000; // Smaller page size for reliability
      
      while (hasMore && page < maxPages) {
        const start = page * fallbackPageSize;
        
        // Create a fresh query for each page
        let query = supabase.from(tableName).select('*', { count: 'exact' });
        
        // Add ordering
        query = query.order(orderBy, { ascending });
        
        // Add range for current page
        query = query.range(start, start + fallbackPageSize - 1);
        
        // Apply filters
        Object.entries(filters).forEach(([key, value]) => {
          if (value !== undefined && value !== null && value !== '') {
            // @ts-ignore
            query = query.eq(key, value);
          }
        });

        console.log(`Fetching ${tableName} page ${page + 1} (${start}-${start + fallbackPageSize - 1})`);
        
        // Multiple retry mechanism for each page
        let pageRetries = 0;
        let pageData = null;
        
        while (pageRetries < 3 && !pageData) {
          try {
            const { data, error } = await query;
            
            if (error) {
              console.error(`Error fetching page ${page + 1} (attempt ${pageRetries + 1}/3):`, error);
              pageRetries++;
              await new Promise(resolve => setTimeout(resolve, 1000 * pageRetries));
            } else {
              pageData = data;
              break;
            }
          } catch (e) {
            console.error(`Exception fetching page ${page + 1} (attempt ${pageRetries + 1}/3):`, e);
            pageRetries++;
            await new Promise(resolve => setTimeout(resolve, 1000 * pageRetries));
          }
        }
        
        if (pageData && pageData.length > 0) {
          console.log(`Received ${pageData.length} records for page ${page + 1}`);
          allResults.push(...pageData as T[]);
        } else {
          console.log(`No data received for page ${page + 1}, stopping pagination`);
          hasMore = false;
        }
        
        // Continue only if we received a full page of results
        hasMore = pageData && pageData.length === fallbackPageSize;
        page++;
      }
    }
    
    console.log(`FINAL RESULT: Fetched ${allResults.length} total records from ${tableName}`);
    return allResults;
  } catch (error) {
    console.error('Critical error in fetchPaginated:', error);
    throw error;
  }
};
