
// This file is automatically generated. Do not edit it directly.
import { createClient } from '@supabase/supabase-js';
import type { Database } from './types';

const SUPABASE_URL = "https://fhyhyfoqzpkzkxbkqcdp.supabase.co";
const SUPABASE_PUBLISHABLE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImZoeWh5Zm9xenBremt4YmtxY2RwIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDY1NjY0ODIsImV4cCI6MjA2MjE0MjQ4Mn0.NluvL4FiDbgKXu_avMaLUgyzQayV4_15vrH64vWfok0";

// Import the supabase client like this:
// import { supabase } from "@/integrations/supabase/client";

export const supabase = createClient<Database>(SUPABASE_URL, SUPABASE_PUBLISHABLE_KEY, {
  auth: {
    persistSession: true,
    autoRefreshToken: true,
    detectSessionInUrl: true,
    storage: typeof window !== 'undefined' ? localStorage : undefined,
    flowType: 'implicit',
  },
  global: {
    headers: {
      'apikey': SUPABASE_PUBLISHABLE_KEY,
      'Authorization': `Bearer ${SUPABASE_PUBLISHABLE_KEY}`,
      'Cache-Control': 'no-cache',
      'Pragma': 'no-cache',
      'X-Client-Info': 'supabase-js/2.x'
    },
    fetch: (url, options) => {
      // Longer timeout for large datasets
      const timeout = 30000; // 30 seconds
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), timeout);
      
      return fetch(url, {
        ...options,
        signal: controller.signal,
        headers: {
          ...options?.headers,
          'apikey': SUPABASE_PUBLISHABLE_KEY,
          'Authorization': `Bearer ${SUPABASE_PUBLISHABLE_KEY}`,
          'Connection': 'keep-alive',
        }
      }).finally(() => clearTimeout(timeoutId));
    }
  },
  db: {
    schema: 'public',
  },
  realtime: {
    params: {
      eventsPerSecond: 10,
    }
  }
});

// Simple batch operation for large datasets
export const batchOperation = async <T>(items: T[], operationFn: (batch: T[]) => Promise<any>, batchSize = 500) => {
  const batches = [];
  
  for (let i = 0; i < items.length; i += batchSize) {
    batches.push(items.slice(i, i + batchSize));
  }
  
  const results = [];
  for (const batch of batches) {
    try {
      const result = await operationFn(batch);
      results.push(result);
    } catch (error) {
      console.error('Batch operation failed:', error);
      throw error;
    }
  }
  
  return results;
};

// Improved single query to fetch ALL records with proper ordering and error handling
export const fetchAllRecords = async (tableName: 'voters' | 'admins'): Promise<any[]> => {
  console.log(`Fetching ALL ${tableName} records in FCFS order`);

  try {
    // Use a more reasonable range instead of 99999
    const { data, error } = await supabase
      .from(tableName)
      .select('*')
      .order('created_at', { ascending: true }) // FCFS order
      .limit(10000); // More reasonable limit
    
    if (error) {
      console.error(`Error fetching ${tableName}:`, error);
      throw error;
    }
    
    console.log(`Successfully fetched ${data?.length || 0} ${tableName} records in FCFS order`);
    return data || [];
    
  } catch (error) {
    console.error('Error in fetchAllRecords:', error);
    // Return empty array instead of throwing to prevent app crash
    return [];
  }
};
